{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchaudio\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from torchsummary import summary\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LibriSpeechOne(Dataset):\n",
    "    def __init__(self, audio, label):\n",
    "        self.audio = audio\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.audio, None, self.label, None, None, None\n",
    "\n",
    "\n",
    "class LibriSpeechDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset_type, data=None):\n",
    "\n",
    "        self.audio_transform = nn.Sequential(\n",
    "            torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
    "            torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
    "            torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
    "        )\n",
    "\n",
    "        self.dataset_dir = \"/home/asblab2/sinarasi/mie1517/new_code/data\"\n",
    "        if dataset_type == \"train\":\n",
    "            self.dataset = torchaudio.datasets.LIBRISPEECH(self.dataset_dir, url=\"train-clean-100\", download=True)\n",
    "        elif dataset_type == \"valid\":\n",
    "            self.dataset = torchaudio.datasets.LIBRISPEECH(self.dataset_dir, url=\"test-clean\", download=True)\n",
    "        elif dataset_type == \"one\":\n",
    "            self.dataset = LibriSpeechOne(*data)\n",
    "        else:\n",
    "            raise Exception(\"Invalid dataset type!\")\n",
    "\n",
    "\n",
    "        self.text_to_int = {\"'\": 0, \" \": 1, \"a\": 2, \"b\": 3, \"c\": 4,\n",
    "                            \"d\": 5, \"e\": 6, \"f\": 7, \"g\": 8, \"h\": 9,\n",
    "                            \"i\": 10, \"j\": 11, \"k\": 12, \"l\": 13, \"m\": 14,\n",
    "                            \"n\": 15, \"o\": 16, \"p\": 17, \"q\": 18, \"r\": 19,\n",
    "                            \"s\": 20, \"t\": 21, \"u\": 22, \"v\": 23, \"w\": 24,\n",
    "                            \"x\": 25, \"y\": 26, \"z\": 27}\n",
    "        self.int_to_text = {v: k for k, v in self.text_to_int.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.dataset[index]\n",
    "        audio, _, sentence, _, _, _ = data\n",
    "        spectogram = self.audio_transform(audio).squeeze(0).transpose(0, 1)\n",
    "        label = [self.text_to_int[s] for s in sentence.lower()]\n",
    "        spectogram_length = spectogram.shape[0] // 2\n",
    "        label_length = len(label)\n",
    "        return spectogram, label, spectogram_length, label_length\n",
    "\n",
    "\n",
    "def collate(data):\n",
    "    \"\"\"\n",
    "    Pad spectograms and labels within the batch to the same length.\n",
    "    \"\"\"\n",
    "    spectograms, labels, spectogram_lengths, label_lengths = [], [], [], []\n",
    "    for spectogram, label, spectogram_length, label_length in data:\n",
    "        spectograms += [torch.Tensor(spectogram)]\n",
    "        labels += [torch.Tensor(label)]\n",
    "        spectogram_lengths += [spectogram_length]\n",
    "        label_lengths += [label_length]\n",
    "    spectograms = nn.utils.rnn.pad_sequence(spectograms, batch_first=True).transpose(1, 2)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectograms, labels, torch.tensor(spectogram_lengths), torch.tensor(label_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNLayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            CNNLayerNorm(n_feats),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(channels, channels, kernel, stride, padding=kernel//2),\n",
    "            CNNLayerNorm(n_feats),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(channels, channels, kernel, stride, padding=kernel//2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x    # (batch, channel, feature, time)\n",
    "        x = self.layers(x)\n",
    "        x += residual\n",
    "        return x        # (batch, channel, feature, time)\n",
    "\n",
    "class BiGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout):\n",
    "        super(BiGRU, self).__init__()\n",
    "        self.bigru = nn.Sequential(\n",
    "            nn.LayerNorm(rnn_dim),\n",
    "            nn.GELU(),\n",
    "            nn.GRU(input_size=rnn_dim, hidden_size=hidden_size, num_layers=1, batch_first=True, bidirectional=True),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.bigru(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ASR(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout, hidden_size, rnn_layers, rescnn_layers, n_mels):\n",
    "\n",
    "        super(ASR, self).__init__()\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.n_mels = n_mels // 2\n",
    "        self.lin_start = 128\n",
    "        self.lin_end = 29\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru_layers = rnn_layers\n",
    "        self.rescnn_layers = rescnn_layers\n",
    "\n",
    "        # Process Mel Spectogram via Residual Conv2D Layers\n",
    "        self.rescnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, stride=2, padding=1),\n",
    "            *[ResidualCNN(32, kernel=3, stride=1, dropout=dropout, n_feats=self.n_mels) for _ in range(rescnn_layers)]\n",
    "        )\n",
    "\n",
    "        # Linear layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.LayerNorm(self.n_mels * 32),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.n_mels * 32, self.hidden_size),\n",
    "            nn.LayerNorm(self.hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(self.dropout)\n",
    "        )\n",
    "\n",
    "        # GRU architecture\n",
    "        self.gru = nn.Sequential(*[\n",
    "                    BiGRU(rnn_dim=hidden_size if i==0 else hidden_size*2,\n",
    "                                    hidden_size=hidden_size, dropout=dropout)\n",
    "                    for i in range(self.gru_layers)\n",
    "                ])\n",
    "\n",
    "        # Linear Layers\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size * 2, self.lin_end),\n",
    "            nn.LayerNorm(self.lin_end),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(self.dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.rescnn_layers(x)\n",
    "        x = x.reshape(x.shape[0], x.shape[1] * x.shape[2], x.shape[3])\n",
    "        x = x.transpose(1,2) # Since linear layers require input of shape (batch, time, channels=n_mels)\n",
    "        x = self.fc1(x)\n",
    "        x = self.gru(x)\n",
    "        x = self.fc2(x)\n",
    "        return x, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hp = {\"batch_size\": 10,\n",
    "      \"learning_rate\": 5e-4,\n",
    "      \"lr_factor\": 0.75,\n",
    "      \"lr_patience\": 10,\n",
    "      \"epochs\": 100,\n",
    "      \"n_mels\": 128,\n",
    "      \"sample_rate\": 16000,\n",
    "      \"dropout\": 0.1,\n",
    "      \"hidden_size\": 512,\n",
    "      \"rnn_layers\": 5,\n",
    "      \"cnn_layers\": 3,\n",
    "      \"architecture\": 1}\n",
    "\n",
    "\n",
    "def compute_validation_loss(net, criterion, dataloader):\n",
    "    net.eval()\n",
    "    losses = []\n",
    "    for data, label, data_len, label_len in tqdm(dataloader):\n",
    "        data, label, data_len, label_len = data.cuda(), label.cuda(), data_len.cuda(), label_len.cuda()\n",
    "        out, _ = net(data)\n",
    "        out = F.log_softmax(out, dim=2)\n",
    "        out = out.transpose(0, 1)\n",
    "        loss = criterion(out, label, data_len, label_len)\n",
    "        losses += [loss.item()]\n",
    "\n",
    "    return sum(losses) / len(losses)\n",
    "\n",
    "\n",
    "def train():\n",
    "\n",
    "    # Create wandb logger\n",
    "    wandb.login()\n",
    "\n",
    "    # Initialize model\n",
    "    asr_model = ASR(hp[\"dropout\"], hp[\"hidden_size\"], hp[\"rnn_layers\"], hp[\"cnn_layers\"], hp[\"n_mels\"])\n",
    "    asr_model = asr_model.cuda()\n",
    "\n",
    "    # Datasets\n",
    "    train_dataset = LibriSpeechDataset(\"train\")\n",
    "    valid_dataset = LibriSpeechDataset(\"valid\")\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                                batch_size=hp[\"batch_size\"],\n",
    "                                shuffle=True,\n",
    "                                collate_fn=collate,\n",
    "                                num_workers=3,\n",
    "                                pin_memory=False)\n",
    "    valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                                batch_size=hp[\"batch_size\"],\n",
    "                                shuffle=False,\n",
    "                                collate_fn=collate,\n",
    "                                num_workers=3,\n",
    "                                pin_memory=False)\n",
    "\n",
    "    # Train\n",
    "    optimizer = optim.Adam(asr_model.parameters(), lr=hp[\"learning_rate\"])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=hp[\"lr_factor\"], patience=hp[\"lr_patience\"])\n",
    "    criterion = nn.CTCLoss(blank=28, zero_infinity=True)\n",
    "\n",
    "    min_valid_loss = 1e10\n",
    "    min_train_loss = 1e10\n",
    "\n",
    "    with wandb.init(project=\"MIE1517\", config=hp):\n",
    "        wandb.watch(asr_model, log=\"all\")\n",
    "\n",
    "        for epoch in range(hp[\"epochs\"]):\n",
    "\n",
    "            asr_model = asr_model.train(True)\n",
    "\n",
    "            train_losses = []\n",
    "            for data, label, data_len, label_len in tqdm(train_loader, desc=\"Epoch {0} / {1}\".format(epoch, hp[\"epochs\"])):\n",
    "                data, label, data_len, label_len = data.cuda(), label.cuda(), data_len.cuda(), label_len.cuda()\n",
    "                out, _ = asr_model(data)\n",
    "                out = F.log_softmax(out, dim=2)\n",
    "                out = out.transpose(0, 1) # CTCLoss takes batch_size as second dim\n",
    "                loss = criterion(out, label, data_len, label_len)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                train_losses += [loss.item()]\n",
    "\n",
    "            train_loss = sum(train_losses) / len(train_losses)\n",
    "            avg_valid_loss = compute_validation_loss(asr_model, criterion, valid_loader)\n",
    "            scheduler.step(avg_valid_loss)\n",
    "\n",
    "            # Save checkpoint if valid loss is at minimum\n",
    "            if avg_valid_loss < min_valid_loss:\n",
    "                print(\"Saved valid checkpoint!\")\n",
    "                torch.save(asr_model.state_dict(), \"/home/asblab2/sinarasi/mie1517/MIE1517-Project/Speech Recog/best_model.pth\")\n",
    "                min_valid_loss = avg_valid_loss\n",
    "            if train_loss < min_train_loss:\n",
    "                print(\"Saved train checkpoint!\")\n",
    "                torch.save(asr_model.state_dict(), \"/home/asblab2/sinarasi/mie1517/MIE1517-Project/Speech Recog/mid_model.pth\")\n",
    "                min_train_loss = train_loss\n",
    "            print(\"Losses:\", train_loss, avg_valid_loss, optimizer.param_groups[0]['lr'])\n",
    "\n",
    "            wandb.log({\"train_loss\": train_loss,\n",
    "                        \"valid_loss\": avg_valid_loss}, step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_isaac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
